{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-N-gs91t8Eok"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oR5oiTrm2_9N",
        "outputId": "6d26d73a-2b14-45c6-8e7d-41c1bc361f0c"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "file_path = \"/content/train_data_merge_0604.csv\"\n",
        "\n",
        "df = pd.read_csv(file_path, encoding='utf-8')\n",
        "\n",
        "print(df.head())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bps4UQdc8gcq",
        "outputId": "8804ab18-d2fb-4830-cea4-a0e2e07f48ec"
      },
      "outputs": [],
      "source": [
        "!pip install -U datasets\n",
        "!pip install -U transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "WZnyKUkz8gfE"
      },
      "outputs": [],
      "source": [
        "# 1. 라이브러리 로딩\n",
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments\n",
        "from datasets import load_dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cccMaqYW8ghi",
        "outputId": "abfb367a-ed56-4fcb-c22e-d6e00e757d28"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# 1. NaN 제거\n",
        "df = df.dropna(subset=[\"context\", \"response\", \"label\"])\n",
        "\n",
        "# 2. 라벨 처리 (공백 제거 및 숫자 매핑)\n",
        "df[\"label\"] = df[\"label\"].str.strip().str.capitalize()  # 'non-sarcasm' -> 'Non-sarcasm'\n",
        "df = df[df[\"label\"].isin([\"Sarcasm\", \"Non-sarcasm\"])].copy()\n",
        "df[\"label\"] = df[\"label\"].map({\"Non-sarcasm\": 0, \"Sarcasm\": 1})\n",
        "\n",
        "# 3. 프롬프트 생성\n",
        "df[\"text\"] = df.apply(\n",
        "    lambda row: f\"다음 상황을 읽고, 이어지는 발언이 풍자(Sarcasm)인지 아닌지 분류하세요.\\n상황: {row['context']}\\n발언: {row['response']}\",\n",
        "    axis=1\n",
        ")\n",
        "\n",
        "# 4. 결과 확인\n",
        "print(df[[\"text\", \"label\"]].sample(3).to_string(index=False))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "C59vnjmy_jad"
      },
      "outputs": [],
      "source": [
        "# 5. 데이터 분리\n",
        "from sklearn.model_selection import train_test_split\n",
        "train_texts, val_texts, train_labels, val_labels = train_test_split(\n",
        "    df[\"text\"].tolist(),\n",
        "    df[\"label\"].tolist(),\n",
        "    test_size=0.2,\n",
        "    stratify=df[\"label\"]\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nLzLV-wC8gl5",
        "outputId": "3547ce42-9db4-46d9-e966-2a0b277d6b62"
      },
      "outputs": [],
      "source": [
        "# 6. 토크나이저 및 모델 로딩\n",
        "model_name = \"monologg/kobert\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)\n",
        "model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "-AVdGDI_8gnE"
      },
      "outputs": [],
      "source": [
        "# pad_token 보완\n",
        "if tokenizer.pad_token is None:\n",
        "    tokenizer.add_special_tokens({'pad_token': '[PAD]'})\n",
        "    model.resize_token_embeddings(len(tokenizer))\n",
        "model.config.pad_token_id = tokenizer.pad_token_id"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "cim0uGHZ8gov"
      },
      "outputs": [],
      "source": [
        "# 7. Dataset 정의\n",
        "class SarcasmDataset(Dataset):\n",
        "    def __init__(self, texts, labels, tokenizer, max_len=128):\n",
        "        self.encodings = tokenizer(texts, truncation=True, padding=\"max_length\", max_length=max_len)\n",
        "        self.labels = labels\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
        "        item[\"labels\"] = torch.tensor(self.labels[idx])\n",
        "        return item"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "AhNz9nhM_Jm0"
      },
      "outputs": [],
      "source": [
        "# 8. Dataset 객체 생성\n",
        "train_dataset = SarcasmDataset(train_texts, train_labels, tokenizer)\n",
        "val_dataset = SarcasmDataset(val_texts, val_labels, tokenizer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G1tpFPoF8grF",
        "outputId": "03a3f96f-d869-49ca-e87a-590646841d9d"
      },
      "outputs": [],
      "source": [
        "# 9. Trainer 설정\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./results\",\n",
        "    save_strategy=\"no\",  # ✅ 모델 저장 기능 제거\n",
        "    learning_rate=5e-5,\n",
        "    per_device_train_batch_size=16,\n",
        "    per_device_eval_batch_size=16,\n",
        "    num_train_epochs=1,\n",
        "    weight_decay=0.01,\n",
        "    logging_dir='./logs',\n",
        "    logging_steps=10,\n",
        "    report_to=\"wandb\",  # or \"none\"\n",
        "    run_name=\"kobert-kocosa-run\"\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=val_dataset,\n",
        "    tokenizer=tokenizer\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 827
        },
        "id": "fgiInO_d8gtZ",
        "outputId": "323a07af-6e85-4636-d6da-d5608e159e80"
      },
      "outputs": [],
      "source": [
        "trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xkib01tO8gyR",
        "outputId": "2ca22de1-a246-4708-f09b-e6ce6c4251a8"
      },
      "outputs": [],
      "source": [
        "###########################################\n",
        "# 9-1. 허깅페이스 로그인\n",
        "\n",
        "# WRITE token\n",
        "!huggingface-cli login --token \"[token]\" # code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "9KpfdbjZE5SR"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoTokenizer\n",
        "import os\n",
        "import shutil\n",
        "\n",
        "# KoBERT 토크나이저 로드\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"monologg/kobert\", trust_remote_code=True)\n",
        "\n",
        "# 저장할 디렉토리 생성\n",
        "save_dir = \"./kobert_sarcasm_tokenizer\"\n",
        "os.makedirs(save_dir, exist_ok=True)\n",
        "\n",
        "# vocab.txt 복사\n",
        "shutil.copyfile(tokenizer.vocab_file, os.path.join(save_dir, \"vocab.txt\"))\n",
        "\n",
        "# 구성 파일 수동 저장\n",
        "with open(os.path.join(save_dir, \"tokenizer_config.json\"), \"w\", encoding=\"utf-8\") as f:\n",
        "    f.write('{\"do_lower_case\": false, \"unk_token\": \"[UNK]\", \"sep_token\": \"[SEP]\", \"pad_token\": \"[PAD]\", \"cls_token\": \"[CLS]\", \"mask_token\": \"[MASK]\"}')\n",
        "\n",
        "with open(os.path.join(save_dir, \"special_tokens_map.json\"), \"w\", encoding=\"utf-8\") as f:\n",
        "    f.write('{\"unk_token\": \"[UNK]\", \"sep_token\": \"[SEP]\", \"pad_token\": \"[PAD]\", \"cls_token\": \"[CLS]\", \"mask_token\": \"[MASK]\"}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "id": "em96hxx_E5V2",
        "outputId": "3d03970a-08e0-4c93-acc3-45682bcc51f4"
      },
      "outputs": [],
      "source": [
        "from huggingface_hub import HfApi\n",
        "\n",
        "api = HfApi()\n",
        "api.upload_folder(\n",
        "    folder_path=save_dir,\n",
        "    repo_id=\"tlttlto/sktBERT\",\n",
        "    path_in_repo=\"\",  # 루트에 업로드\n",
        "    repo_type=\"model\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qGBOZJ4kE5XP",
        "outputId": "606afb43-716f-421d-c55c-dd3e257e6d4a"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoTokenizer\n",
        "\n",
        "tok = AutoTokenizer.from_pretrained(\"monologg/kobert\", trust_remote_code=True)\n",
        "print(tok.vocab_file)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "65n-GIfLE5Zu"
      },
      "outputs": [],
      "source": [
        "import shutil\n",
        "import os\n",
        "\n",
        "model_file = tok.vocab_file  # .model 파일 경로\n",
        "\n",
        "# 저장 디렉토리\n",
        "save_dir = \"./kobert_sarcasm_tokenizer\"\n",
        "os.makedirs(save_dir, exist_ok=True)\n",
        "\n",
        "# SentencePiece 모델 복사 (핵심)\n",
        "shutil.copyfile(model_file, os.path.join(save_dir, \"tokenizer_78b3253a26.model\"))\n",
        "\n",
        "# 구성 파일 생성\n",
        "with open(os.path.join(save_dir, \"tokenizer_config.json\"), \"w\", encoding=\"utf-8\") as f:\n",
        "    f.write('{\"tokenizer_class\": \"KoBertTokenizer\"}')\n",
        "\n",
        "with open(os.path.join(save_dir, \"special_tokens_map.json\"), \"w\", encoding=\"utf-8\") as f:\n",
        "    f.write('{\"unk_token\": \"[UNK]\", \"sep_token\": \"[SEP]\", \"pad_token\": \"[PAD]\", \"cls_token\": \"[CLS]\", \"mask_token\": \"[MASK]\"}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "id": "rQjg91oaE5cM",
        "outputId": "aef601a9-2379-4143-a7cf-c9554e695364"
      },
      "outputs": [],
      "source": [
        "from huggingface_hub import HfApi, login\n",
        "\n",
        "login(\"[token]\")  # 또는 login(\"hf_...\")\n",
        "\n",
        "api = HfApi()\n",
        "api.upload_folder(\n",
        "    folder_path=save_dir,\n",
        "    repo_id=\"tlttlto/sktBERT\",\n",
        "    path_in_repo=\"\",\n",
        "    repo_type=\"model\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "6Gt41GGAFETX"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import DataLoader, Dataset\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "import torch\n",
        "\n",
        "# 평가용 Dataset 클래스\n",
        "class SarcasmDataset(Dataset):\n",
        "    def __init__(self, texts, labels, tokenizer, max_len=128):\n",
        "        self.encodings = tokenizer(texts, truncation=True, padding=\"max_length\", max_length=max_len)\n",
        "        self.labels = labels\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
        "        item[\"labels\"] = torch.tensor(self.labels[idx])\n",
        "        return item"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_VJ1RLUAFEV6",
        "outputId": "d325ef6a-85bb-45d3-c64b-6b3bd9465699"
      },
      "outputs": [],
      "source": [
        "from transformers import BertTokenizer\n",
        "\n",
        "# 다시 불러오기\n",
        "tokenizer = BertTokenizer.from_pretrained(\"monologg/kobert\", do_lower_case=False)\n",
        "\n",
        "# 저장\n",
        "tokenizer.save_pretrained(\"./finetuned_model\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "pL7pJh2rFEYo"
      },
      "outputs": [],
      "source": [
        "model.save_pretrained(\"./finetuned_model\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "PKz8K3dVFEbR"
      },
      "outputs": [],
      "source": [
        "from transformers import BertTokenizer, AutoModelForSequenceClassification\n",
        "\n",
        "tokenizer = BertTokenizer.from_pretrained(\"./finetuned_model\")\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\"./finetuned_model\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "br7wkmF-FEdv",
        "outputId": "1154799a-852e-47c6-e7c1-7fd044aef799"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from transformers import BertTokenizer, AutoModelForSequenceClassification\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "\n",
        "# ✅ 1. 저장된 모델 경로\n",
        "model_path = \"./finetuned_model\"\n",
        "\n",
        "# ✅ 2. 저장된 모델과 토크나이저 불러오기\n",
        "tokenizer = BertTokenizer.from_pretrained(model_path)\n",
        "model = AutoModelForSequenceClassification.from_pretrained(model_path)\n",
        "model.eval()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "BAZ6KFjVFEhh"
      },
      "outputs": [],
      "source": [
        "# ✅ 3. 평가용 데이터셋 클래스 정의\n",
        "class SarcasmDataset(Dataset):\n",
        "    def __init__(self, texts, labels, tokenizer, max_len=128):\n",
        "        self.encodings = tokenizer(texts, truncation=True, padding=\"max_length\", max_length=max_len)\n",
        "        self.labels = labels\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
        "        item[\"labels\"] = torch.tensor(self.labels[idx])\n",
        "        return item"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "5fAsxoa5E5eu"
      },
      "outputs": [],
      "source": [
        "# ✅ 4. 평가 데이터셋 구성 (이미 존재하는 val_texts, val_labels 사용)\n",
        "eval_dataset = SarcasmDataset(val_texts, val_labels, tokenizer)\n",
        "eval_loader = DataLoader(eval_dataset, batch_size=16)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UMgetEkmE5iM",
        "outputId": "27fb2976-a3fc-4ada-d3ac-5f1fb859b3ee"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "평가 진행 중: 100%|██████████| 50/50 [04:49<00:00,  5.80s/it]\n"
          ]
        }
      ],
      "source": [
        "from tqdm import tqdm  # 진행률 표시\n",
        "\n",
        "all_preds = []\n",
        "all_labels = []\n",
        "\n",
        "# tqdm으로 eval_loader 감싸기\n",
        "with torch.no_grad():\n",
        "    for batch in tqdm(eval_loader, desc=\"평가 진행 중\"):\n",
        "        input_ids = batch[\"input_ids\"]\n",
        "        attention_mask = batch[\"attention_mask\"]\n",
        "        labels = batch[\"labels\"]\n",
        "\n",
        "        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
        "        preds = torch.argmax(outputs.logits, dim=1)\n",
        "\n",
        "        all_preds.extend(preds.tolist())\n",
        "        all_labels.extend(labels.tolist())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e7ZBJFj6FTYM",
        "outputId": "e9dd9ea2-79a1-4752-ec5a-e34efcd039d3"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "\n",
        "# 평가 결과 출력\n",
        "print(\"분류 리포트:\\n\")\n",
        "print(classification_report(all_labels, all_preds, digits=4))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x4dch9ESFTfs",
        "outputId": "90ddc569-3768-4637-d759-a83c3c143bce"
      },
      "outputs": [],
      "source": [
        "from collections import Counter\n",
        "print(\"예측 결과 분포:\", Counter(all_preds))\n",
        "\n",
        "for i in range(20):\n",
        "    print(f\"\\n[예시 {i+1}]\")\n",
        "    print(\"문장:\", val_texts[i])\n",
        "    print(\"실제 라벨:\", val_labels[i])\n",
        "    print(\"예측 라벨:\", all_preds[i])\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
