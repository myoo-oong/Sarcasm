{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oR5oiTrm2_9N",
        "outputId": "96952948-70fa-4975-f7b3-d5d3959f8f7a"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "file_path = \"/content/train_data_merge_0604.csv\"\n",
        "\n",
        "df = pd.read_csv(file_path, encoding='utf-8')\n",
        "\n",
        "print(df.head())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bps4UQdc8gcq",
        "outputId": "6e03a376-bf3b-42e9-95c1-d34b74eca1d8"
      },
      "outputs": [],
      "source": [
        "!pip install -U datasets\n",
        "!pip install -U transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "WZnyKUkz8gfE"
      },
      "outputs": [],
      "source": [
        "# 1. 라이브러리 로딩\n",
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments\n",
        "from datasets import load_dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cccMaqYW8ghi",
        "outputId": "6b7770db-e230-46b8-c6e7-d09da66d509e"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# 1. NaN 제거\n",
        "df = df.dropna(subset=[\"context\", \"response\", \"label\"])\n",
        "\n",
        "# 2. 라벨 처리 (공백 제거 및 숫자 매핑)\n",
        "df[\"label\"] = df[\"label\"].str.strip().str.capitalize()  # 'non-sarcasm' -> 'Non-sarcasm'\n",
        "df = df[df[\"label\"].isin([\"Sarcasm\", \"Non-sarcasm\"])].copy()\n",
        "df[\"label\"] = df[\"label\"].map({\"Non-sarcasm\": 0, \"Sarcasm\": 1})\n",
        "\n",
        "# 3. 프롬프트 생성\n",
        "df[\"text\"] = df.apply(\n",
        "    lambda row: f\"다음 상황을 읽고, 이어지는 발언이 풍자(Sarcasm)인지 아닌지 분류하세요.\\n상황: {row['context']}\\n발언: {row['response']}\",\n",
        "    axis=1\n",
        ")\n",
        "\n",
        "# 4. 결과 확인\n",
        "print(df[[\"text\", \"label\"]].sample(3).to_string(index=False))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "C59vnjmy_jad"
      },
      "outputs": [],
      "source": [
        "# 5. 데이터 분리\n",
        "from sklearn.model_selection import train_test_split\n",
        "train_texts, val_texts, train_labels, val_labels = train_test_split(\n",
        "    df[\"text\"].tolist(),\n",
        "    df[\"label\"].tolist(),\n",
        "    test_size=0.2,\n",
        "    stratify=df[\"label\"]\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nLzLV-wC8gl5",
        "outputId": "dc6b3fda-fcad-40ac-e69b-85aaadb814f0"
      },
      "outputs": [],
      "source": [
        "# 6. 토크나이저 및 모델 로딩\n",
        "model_name = \"monologg/kobert\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)\n",
        "model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "-AVdGDI_8gnE"
      },
      "outputs": [],
      "source": [
        "# pad_token 보완\n",
        "if tokenizer.pad_token is None:\n",
        "    tokenizer.add_special_tokens({'pad_token': '[PAD]'})\n",
        "    model.resize_token_embeddings(len(tokenizer))\n",
        "model.config.pad_token_id = tokenizer.pad_token_id"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "cim0uGHZ8gov"
      },
      "outputs": [],
      "source": [
        "# 7. Dataset 정의\n",
        "class SarcasmDataset(Dataset):\n",
        "    def __init__(self, texts, labels, tokenizer, max_len=128):\n",
        "        self.encodings = tokenizer(texts, truncation=True, padding=\"max_length\", max_length=max_len)\n",
        "        self.labels = labels\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
        "        item[\"labels\"] = torch.tensor(self.labels[idx])\n",
        "        return item"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "AhNz9nhM_Jm0"
      },
      "outputs": [],
      "source": [
        "# 8. Dataset 객체 생성\n",
        "train_dataset = SarcasmDataset(train_texts, train_labels, tokenizer)\n",
        "val_dataset = SarcasmDataset(val_texts, val_labels, tokenizer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G1tpFPoF8grF",
        "outputId": "b63e5b39-7a35-4d7e-9328-f214e0b7e7c7"
      },
      "outputs": [],
      "source": [
        "# 9. Trainer 설정\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./results\",\n",
        "    save_strategy=\"no\",  # ✅ 모델 저장 기능 제거\n",
        "    learning_rate=5e-5,\n",
        "    per_device_train_batch_size=16,\n",
        "    per_device_eval_batch_size=16,\n",
        "    num_train_epochs=3,\n",
        "    weight_decay=0.01,\n",
        "    logging_dir='./logs',\n",
        "    logging_steps=10,\n",
        "    report_to=\"wandb\",  # or \"none\"\n",
        "    run_name=\"kobert-kocosa-run\"\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=val_dataset,\n",
        "    tokenizer=tokenizer\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "fgiInO_d8gtZ",
        "outputId": "710c9327-dc01-4b2f-9083-35a0e2b8b545"
      },
      "outputs": [],
      "source": [
        "trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xkib01tO8gyR",
        "outputId": "c688b8e3-da0c-4696-921a-1acfad40cbe5"
      },
      "outputs": [],
      "source": [
        "###########################################\n",
        "# 9-1. 허깅페이스 로그인\n",
        "\n",
        "# WRITE token\n",
        "!huggingface-cli login --token  # code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "9KpfdbjZE5SR"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoTokenizer\n",
        "import os\n",
        "import shutil\n",
        "\n",
        "# KoBERT 토크나이저 로드\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"monologg/kobert\", trust_remote_code=True)\n",
        "\n",
        "# 저장할 디렉토리 생성\n",
        "save_dir = \"./kobert_sarcasm_tokenizer\"\n",
        "os.makedirs(save_dir, exist_ok=True)\n",
        "\n",
        "# vocab.txt 복사\n",
        "shutil.copyfile(tokenizer.vocab_file, os.path.join(save_dir, \"vocab.txt\"))\n",
        "\n",
        "# 구성 파일 수동 저장\n",
        "with open(os.path.join(save_dir, \"tokenizer_config.json\"), \"w\", encoding=\"utf-8\") as f:\n",
        "    f.write('{\"do_lower_case\": false, \"unk_token\": \"[UNK]\", \"sep_token\": \"[SEP]\", \"pad_token\": \"[PAD]\", \"cls_token\": \"[CLS]\", \"mask_token\": \"[MASK]\"}')\n",
        "\n",
        "with open(os.path.join(save_dir, \"special_tokens_map.json\"), \"w\", encoding=\"utf-8\") as f:\n",
        "    f.write('{\"unk_token\": \"[UNK]\", \"sep_token\": \"[SEP]\", \"pad_token\": \"[PAD]\", \"cls_token\": \"[CLS]\", \"mask_token\": \"[MASK]\"}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "id": "em96hxx_E5V2",
        "outputId": "2e8050f2-db9d-4eb7-d941-c1cfef83d4bc"
      },
      "outputs": [],
      "source": [
        "from huggingface_hub import HfApi\n",
        "\n",
        "api = HfApi()\n",
        "api.upload_folder(\n",
        "    folder_path=save_dir,\n",
        "    repo_id=\"tlttlto/sktBERT\",\n",
        "    path_in_repo=\"\",  # 루트에 업로드\n",
        "    repo_type=\"model\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qGBOZJ4kE5XP",
        "outputId": "f751bb89-66aa-4491-bc7b-55899d381389"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoTokenizer\n",
        "\n",
        "tok = AutoTokenizer.from_pretrained(\"monologg/kobert\", trust_remote_code=True)\n",
        "print(tok.vocab_file)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "65n-GIfLE5Zu"
      },
      "outputs": [],
      "source": [
        "import shutil\n",
        "import os\n",
        "\n",
        "model_file = tok.vocab_file  # .model 파일 경로\n",
        "\n",
        "# 저장 디렉토리\n",
        "save_dir = \"./kobert_sarcasm_tokenizer\"\n",
        "os.makedirs(save_dir, exist_ok=True)\n",
        "\n",
        "# SentencePiece 모델 복사 (핵심)\n",
        "shutil.copyfile(model_file, os.path.join(save_dir, \"tokenizer_78b3253a26.model\"))\n",
        "\n",
        "# 구성 파일 생성\n",
        "with open(os.path.join(save_dir, \"tokenizer_config.json\"), \"w\", encoding=\"utf-8\") as f:\n",
        "    f.write('{\"tokenizer_class\": \"KoBertTokenizer\"}')\n",
        "\n",
        "with open(os.path.join(save_dir, \"special_tokens_map.json\"), \"w\", encoding=\"utf-8\") as f:\n",
        "    f.write('{\"unk_token\": \"[UNK]\", \"sep_token\": \"[SEP]\", \"pad_token\": \"[PAD]\", \"cls_token\": \"[CLS]\", \"mask_token\": \"[MASK]\"}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "id": "rQjg91oaE5cM",
        "outputId": "436a0682-e115-4225-bd66-2e6cf734e94f"
      },
      "outputs": [],
      "source": [
        "from huggingface_hub import HfApi, login\n",
        "\n",
        "login(\"{code}\")  # 또는 login(\"hf_...\")\n",
        "\n",
        "api = HfApi()\n",
        "api.upload_folder(\n",
        "    folder_path=save_dir,\n",
        "    repo_id=\"tlttlto/sktBERT\",\n",
        "    path_in_repo=\"\",\n",
        "    repo_type=\"model\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "6Gt41GGAFETX"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import DataLoader, Dataset\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "import torch\n",
        "\n",
        "# 평가용 Dataset 클래스\n",
        "class SarcasmDataset(Dataset):\n",
        "    def __init__(self, texts, labels, tokenizer, max_len=128):\n",
        "        self.encodings = tokenizer(texts, truncation=True, padding=\"max_length\", max_length=max_len)\n",
        "        self.labels = labels\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
        "        item[\"labels\"] = torch.tensor(self.labels[idx])\n",
        "        return item"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_VJ1RLUAFEV6",
        "outputId": "c36840c0-8e85-46e3-88d7-4facbdf5b308"
      },
      "outputs": [],
      "source": [
        "from transformers import BertTokenizer\n",
        "\n",
        "# 다시 불러오기\n",
        "tokenizer = BertTokenizer.from_pretrained(\"monologg/kobert\", do_lower_case=False)\n",
        "\n",
        "# 저장\n",
        "tokenizer.save_pretrained(\"./finetuned_model\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "pL7pJh2rFEYo"
      },
      "outputs": [],
      "source": [
        "model.save_pretrained(\"./finetuned_model\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "PKz8K3dVFEbR"
      },
      "outputs": [],
      "source": [
        "from transformers import BertTokenizer, AutoModelForSequenceClassification\n",
        "\n",
        "tokenizer = BertTokenizer.from_pretrained(\"./finetuned_model\")\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\"./finetuned_model\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "br7wkmF-FEdv",
        "outputId": "97ec3b99-b1fe-4915-a102-798aad4294cb"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from transformers import BertTokenizer, AutoModelForSequenceClassification\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "\n",
        "# ✅ 1. 저장된 모델 경로\n",
        "model_path = \"./finetuned_model\"\n",
        "\n",
        "# ✅ 2. 저장된 모델과 토크나이저 불러오기\n",
        "tokenizer = BertTokenizer.from_pretrained(model_path)\n",
        "model = AutoModelForSequenceClassification.from_pretrained(model_path)\n",
        "model.eval()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "BAZ6KFjVFEhh"
      },
      "outputs": [],
      "source": [
        "# ✅ 3. 평가용 데이터셋 클래스 정의\n",
        "class SarcasmDataset(Dataset):\n",
        "    def __init__(self, texts, labels, tokenizer, max_len=128):\n",
        "        self.encodings = tokenizer(texts, truncation=True, padding=\"max_length\", max_length=max_len)\n",
        "        self.labels = labels\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
        "        item[\"labels\"] = torch.tensor(self.labels[idx])\n",
        "        return item"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "5fAsxoa5E5eu"
      },
      "outputs": [],
      "source": [
        "# ✅ 4. 평가 데이터셋 구성 (이미 존재하는 val_texts, val_labels 사용)\n",
        "eval_dataset = SarcasmDataset(val_texts, val_labels, tokenizer)\n",
        "eval_loader = DataLoader(eval_dataset, batch_size=16)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UMgetEkmE5iM",
        "outputId": "17393ec3-b599-4ac2-8c1c-c503474fd9f4"
      },
      "outputs": [],
      "source": [
        "from tqdm import tqdm  # 진행률 표시\n",
        "\n",
        "all_preds = []\n",
        "all_labels = []\n",
        "\n",
        "# tqdm으로 eval_loader 감싸기\n",
        "with torch.no_grad():\n",
        "    for batch in tqdm(eval_loader, desc=\"평가 진행 중\"):\n",
        "        input_ids = batch[\"input_ids\"]\n",
        "        attention_mask = batch[\"attention_mask\"]\n",
        "        labels = batch[\"labels\"]\n",
        "\n",
        "        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
        "        preds = torch.argmax(outputs.logits, dim=1)\n",
        "\n",
        "        all_preds.extend(preds.tolist())\n",
        "        all_labels.extend(labels.tolist())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e7ZBJFj6FTYM",
        "outputId": "4a4ac687-19b6-4e3c-9772-df1e63fd392d"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "\n",
        "# 평가 결과 출력\n",
        "print(\"분류 리포트:\\n\")\n",
        "print(classification_report(all_labels, all_preds, digits=4))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x4dch9ESFTfs",
        "outputId": "36fac737-870b-45a0-f9ba-f63bd58b9c8b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "예측 결과 분포: Counter({1: 485, 0: 315})\n",
            "\n",
            "[예시 1]\n",
            "문장: 다음 상황을 읽고, 이어지는 발언이 풍자(Sarcasm)인지 아닌지 분류하세요.\n",
            "상황: 아기가 좁쌀베개를 불편해하고 잘 사용하지 못하는 상황\n",
            "발언: 아기를 위해 더 편안한 베개를 찾아보는 것이 좋겠어요.\n",
            "실제 라벨: 0\n",
            "예측 라벨: 0\n",
            "\n",
            "[예시 2]\n",
            "문장: 다음 상황을 읽고, 이어지는 발언이 풍자(Sarcasm)인지 아닌지 분류하세요.\n",
            "상황: 게임 자체는 재미있지만, 불필요한 업데이트에 대한 불만을 나타낸 리뷰\n",
            "발언: 게임은 재미있지만, 불필요한 업데이트가 많아 불편합니다.\n",
            "실제 라벨: 0\n",
            "예측 라벨: 0\n",
            "\n",
            "[예시 3]\n",
            "문장: 다음 상황을 읽고, 이어지는 발언이 풍자(Sarcasm)인지 아닌지 분류하세요.\n",
            "상황: 여자친구의 늦은 답장 때문에 화가 난 남자의 고민에 대한 대화\n",
            "발언: 요즘 많이 바쁜가 보네. 답장이 늦으면 조금 서운해.\n",
            "실제 라벨: 0\n",
            "예측 라벨: 1\n",
            "\n",
            "[예시 4]\n",
            "문장: 다음 상황을 읽고, 이어지는 발언이 풍자(Sarcasm)인지 아닌지 분류하세요.\n",
            "상황: 글쓴이는 밥 말리와 같은 진정성을 가진 가수가 현대에는 없다고 느끼고 있다. 현대 가수들은 외모와 비주얼에만 집중하고, 진정한 음악적 메시지가 부족하다고 비판하고 있다. 또한, 정치인들도 철학 없이 이익만을 추구하는 모습을 비판하고 있다.\n",
            "발언: 현대 음악 산업은 외적인 요소에 지나치게 의존하고 있어 진정한 예술성과 메시지가 사라지고 있는 것 같습니다.\n",
            "실제 라벨: 0\n",
            "예측 라벨: 1\n",
            "\n",
            "[예시 5]\n",
            "문장: 다음 상황을 읽고, 이어지는 발언이 풍자(Sarcasm)인지 아닌지 분류하세요.\n",
            "상황: 사람들이 뱀을 키우는 것에 대한 두려움과 혐오감을 나누는 대화\n",
            "발언: 뱀을 집에서 키우면 매일매일 서바이벌 게임이겠네요!\n",
            "실제 라벨: 1\n",
            "예측 라벨: 1\n",
            "\n",
            "[예시 6]\n",
            "문장: 다음 상황을 읽고, 이어지는 발언이 풍자(Sarcasm)인지 아닌지 분류하세요.\n",
            "상황: 버스비 상승으로 인한 경제적 부담과 서울로의 이동 이유에 대한 대화\n",
            "발언: 아, 버스비 오르는 게 마치 서울 여행을 더 특별하게 만들어 주려는 의도인 것 같네요. 보너스로 경제적 부담도 덤으로 주고요!\n",
            "실제 라벨: 1\n",
            "예측 라벨: 1\n",
            "\n",
            "[예시 7]\n",
            "문장: 다음 상황을 읽고, 이어지는 발언이 풍자(Sarcasm)인지 아닌지 분류하세요.\n",
            "상황: 국민의례를 통해서만 나라사랑을 평가하는 것에 대한 비판과 다양한 방식의 나라사랑 표현을 존중해야 한다는 주장\n",
            "발언: 나라를 사랑하는 방법이 국민의례 말고도 많다고요? 그럼 이제부터는 애국심이란 단어도 사전에서 삭제해야겠네요!\n",
            "실제 라벨: 1\n",
            "예측 라벨: 1\n",
            "\n",
            "[예시 8]\n",
            "문장: 다음 상황을 읽고, 이어지는 발언이 풍자(Sarcasm)인지 아닌지 분류하세요.\n",
            "상황: 연애 중 기념일 통장이나 커플 통장에 대한 의견과 그에 대한 부정적인 생각을 나누는 대화\n",
            "발언: 기념일 통장은 오히려 서로의 독립성을 침해하고, 자칫하면 불필요한 갈등을 불러올 것 같아.\n",
            "실제 라벨: 0\n",
            "예측 라벨: 1\n",
            "\n",
            "[예시 9]\n",
            "문장: 다음 상황을 읽고, 이어지는 발언이 풍자(Sarcasm)인지 아닌지 분류하세요.\n",
            "상황: 자녀의 태권도 복장을 잘못 가져온 사건으로 인해 부모가 불쾌감을 느끼고 대화하는 상황\n",
            "발언: 다음에는 꼭 맞는 복장을 챙길 수 있도록 더 신경 써야겠어요.\n",
            "실제 라벨: 0\n",
            "예측 라벨: 1\n",
            "\n",
            "[예시 10]\n",
            "문장: 다음 상황을 읽고, 이어지는 발언이 풍자(Sarcasm)인지 아닌지 분류하세요.\n",
            "상황: A: 휴일에는 어떻게 보내시나요?\n",
            "B: 아무래도 혼자 있는 시간을 좋아해서 주로 혼자 보내곤 합니다.\n",
            "A: 그렇군요. 혹시 특별히 하시는 활동이 있으신가요?\n",
            "B: 저는 주로 커피를 한잔 마시면서 책을 읽는 걸 좋아합니다. \n",
            "발언: A: 와, 당신의 휴일은 정말로 화려하군요.\n",
            "실제 라벨: 1\n",
            "예측 라벨: 1\n",
            "\n",
            "[예시 11]\n",
            "문장: 다음 상황을 읽고, 이어지는 발언이 풍자(Sarcasm)인지 아닌지 분류하세요.\n",
            "상황: 군대의 급식 상황과 관련된 불만과 논란에 대한 대화\n",
            "발언: 와, 이런 멋진 미쉐린 스타급 요리 덕분에 군입대가 한층 기대되는데요!\n",
            "실제 라벨: 1\n",
            "예측 라벨: 1\n",
            "\n",
            "[예시 12]\n",
            "문장: 다음 상황을 읽고, 이어지는 발언이 풍자(Sarcasm)인지 아닌지 분류하세요.\n",
            "상황: 고양이를 키우는 것에 대한 어려움과 털 문제, 야행성 특성에 대한 대화\n",
            "발언: 고양이를 키우면서 털과 밤에 활동적인 성격 때문에 관리는 좀 어렵지만, 그래도 정말 사랑스러워요.\n",
            "실제 라벨: 0\n",
            "예측 라벨: 1\n",
            "\n",
            "[예시 13]\n",
            "문장: 다음 상황을 읽고, 이어지는 발언이 풍자(Sarcasm)인지 아닌지 분류하세요.\n",
            "상황: B: 서울에서 자전거를 이용하시는데 어려움이 있으셨나요?\n",
            "A: 아니요, 따름이가 있어서 편하게 이용하고 있습니다.\n",
            "B: 따름이의 어떤 기능을 가장 유용하게 사용하셨나요?\n",
            "A: 따름이의 GPS 기능이 정말 편리합니다. 하지만 종종 위치정보가 정확하지 않아 조금 불편하기도 합니다.\n",
            "발언: B: 그럼 이제 더 재미있는 경로를 찾아볼 수 있겠네요.\n",
            "실제 라벨: 1\n",
            "예측 라벨: 1\n",
            "\n",
            "[예시 14]\n",
            "문장: 다음 상황을 읽고, 이어지는 발언이 풍자(Sarcasm)인지 아닌지 분류하세요.\n",
            "상황: 어린 시절 친구를 오랜만에 만났더니 시간이 많이 흘러 서로 나이가 들었음을 깨닫는 상황\n",
            "발언: 정말 오랜만이야! 우리가 이렇게 나이가 들었구나.\n",
            "실제 라벨: 0\n",
            "예측 라벨: 1\n",
            "\n",
            "[예시 15]\n",
            "문장: 다음 상황을 읽고, 이어지는 발언이 풍자(Sarcasm)인지 아닌지 분류하세요.\n",
            "상황: 배송된 상품의 파손에 대한 고객 불만 리뷰\n",
            "발언: 이제 깨진 걸로 조각 맞추기 게임이라도 해야겠네요.\n",
            "실제 라벨: 1\n",
            "예측 라벨: 0\n",
            "\n",
            "[예시 16]\n",
            "문장: 다음 상황을 읽고, 이어지는 발언이 풍자(Sarcasm)인지 아닌지 분류하세요.\n",
            "상황: 스트레스가 건강에 악영향을 미치는 상황\n",
            "발언: 네, 스트레스 덕분에 병원비로 경제가 활성화되고 있죠!\n",
            "실제 라벨: 1\n",
            "예측 라벨: 1\n",
            "\n",
            "[예시 17]\n",
            "문장: 다음 상황을 읽고, 이어지는 발언이 풍자(Sarcasm)인지 아닌지 분류하세요.\n",
            "상황: A: 베스킨에 갈 생각이신가요?\n",
            "B: 네, 오늘 쿠폰이 있어서 가려고 합니다.\n",
            "A: 좋은 선택이시네요. 어떤 맛을 좋아하시나요?\n",
            "B: 저는 그린 티 맛을 좋아하는데, 요즘은 뉴욕치즈 맛이 안 보이더라고요.\n",
            "A: 아, 그럼 요즘 무슨 맛을 즐겨 드시나요?\n",
            "B: 요즘은 바람과 함께 사라지다는 맛을 먹고 있는데, 이거 한눈팔면 없어져서 항상 먹어야만 해요.\n",
            "발언: A: 그러니까 아이스크림을 지켜야 하는 연인이 있으신 거군요.\n",
            "실제 라벨: 0\n",
            "예측 라벨: 0\n",
            "\n",
            "[예시 18]\n",
            "문장: 다음 상황을 읽고, 이어지는 발언이 풍자(Sarcasm)인지 아닌지 분류하세요.\n",
            "상황: 게임의 스토리 길이와 후속 콘텐츠 부족에 대한 불만 리뷰\n",
            "발언: 게임의 스토리가 너무 짧고 후속 콘텐츠가 부족하여 아쉽습니다.\n",
            "실제 라벨: 0\n",
            "예측 라벨: 0\n",
            "\n",
            "[예시 19]\n",
            "문장: 다음 상황을 읽고, 이어지는 발언이 풍자(Sarcasm)인지 아닌지 분류하세요.\n",
            "상황: 게임의 아트와 세계관에 대한 긍정적인 시작과 이후의 흥미 감소에 대한 리뷰\n",
            "발언: 처음에는 아트와 세계관이 매력적이었지만, 게임을 진행하면서 점점 흥미를 잃게 되었습니다.\n",
            "실제 라벨: 0\n",
            "예측 라벨: 0\n",
            "\n",
            "[예시 20]\n",
            "문장: 다음 상황을 읽고, 이어지는 발언이 풍자(Sarcasm)인지 아닌지 분류하세요.\n",
            "상황: 주말 점심 시간에 영화관이 거의 비어 있는 상황\n",
            "발언: 이 시간대에 영화관이 한산해서 편안하게 영화를 볼 수 있겠네요.\n",
            "실제 라벨: 0\n",
            "예측 라벨: 1\n"
          ]
        }
      ],
      "source": [
        "from collections import Counter\n",
        "print(\"예측 결과 분포:\", Counter(all_preds))\n",
        "\n",
        "for i in range(20):\n",
        "    print(f\"\\n[예시 {i+1}]\")\n",
        "    print(\"문장:\", val_texts[i])\n",
        "    print(\"실제 라벨:\", val_labels[i])\n",
        "    print(\"예측 라벨:\", all_preds[i])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "xi1VyObNFTi_"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "Hl4q81oSFTmC"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
