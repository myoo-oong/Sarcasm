{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "707a5c74",
   "metadata": {},
   "source": [
    "## 🐾 OpenAI API 키 발급 및 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "55cba5aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# API KEY를 환경변수로 관리하기 위한 설정 파일\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# API KEY 정보로드\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1ce4f545",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[API KEY]\n",
      "sk-proj-y4WToRFYqZ-Wj0gO27S4wqQdFi4npu7mKV5RFHUEcIBuE_riXH0aLGMjXEHMztDkz0VQc1I0hsT3BlbkFJq0VCbNlLt9D-MkAmmk_8eyCar687htSINT9IDo93U4--tA7Vzefg0tpbh9s***************\n"
     ]
    }
   ],
   "source": [
    "# API KEY 정보 확인\n",
    "import os\n",
    "\n",
    "print(f\"[API KEY]\\n{os.environ['OPENAI_API_KEY'][:-15]}\" + \"*\" * 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c02d0483",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LangChain 관련 패키지 버전]\n",
      "langchain: 0.3.23\n",
      "langchain-core: 0.3.51\n",
      "langchain-experimental: 0.3.4\n",
      "langchain-community: 0.3.21\n",
      "langchain-openai: 0.3.12\n",
      "langchain-teddynote: 0.3.45\n",
      "langchain-huggingface: 0.1.2\n",
      "langchain-google-genai: 2.1.2\n",
      "langchain-anthropic: 0.3.10\n",
      "langchain-cohere: 0.4.3\n",
      "langchain-chroma: 0.2.2\n",
      "langchain-elasticsearch: 0.3.2\n",
      "langchain-upstage: 설치되지 않음\n",
      "langchain-cohere: 0.4.3\n",
      "langchain-milvus: 0.1.9\n",
      "langchain-text-splitters: 0.3.8\n"
     ]
    }
   ],
   "source": [
    "# LangCahin 버전 확인\n",
    "from importlib.metadata import version\n",
    "\n",
    "print(\"[LangChain 관련 패키지 버전]\")\n",
    "for package_name in [\n",
    "    \"langchain\",\n",
    "    \"langchain-core\",\n",
    "    \"langchain-experimental\",\n",
    "    \"langchain-community\",\n",
    "    \"langchain-openai\",\n",
    "    \"langchain-teddynote\",\n",
    "    \"langchain-huggingface\",\n",
    "    \"langchain-google-genai\",\n",
    "    \"langchain-anthropic\",\n",
    "    \"langchain-cohere\",\n",
    "    \"langchain-chroma\",\n",
    "    \"langchain-elasticsearch\",\n",
    "    \"langchain-upstage\",\n",
    "    \"langchain-cohere\",\n",
    "    \"langchain-milvus\",\n",
    "    \"langchain-text-splitters\",\n",
    "]:\n",
    "    try:\n",
    "        package_version = version(package_name)\n",
    "        print(f\"{package_name}: {package_version}\")\n",
    "    except ImportError:\n",
    "        print(f\"{package_name}: 설치되지 않음\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8093faf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LangSmith 추적을 시작합니다.\n",
      "[프로젝트명]\n",
      "PromptIkkyunFinal\n"
     ]
    }
   ],
   "source": [
    "# # LangSmith 추적 설정 https://smith.langchain.com\n",
    "# # .env 파일에 LANGCHAIN_API_KEY 입력\n",
    "# # !pip install -qU langchain-teddynote\n",
    "# from langchain_teddynote import logging\n",
    "\n",
    "# # 프로젝트 이름을 입력\n",
    "# logging.langsmith(\"***\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e913cd91",
   "metadata": {},
   "source": [
    "## 🐻 데이터셋 1000개 최종ver\n",
    "부정 리뷰 500개 (1000 rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6551a10c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No `_type` key found, defaulting to `prompt`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "진행 상황: 0 / 500 문장 처리 완료\n",
      "진행 상황: 100 / 500 문장 처리 완료\n",
      "진행 상황: 200 / 500 문장 처리 완료\n",
      "진행 상황: 300 / 500 문장 처리 완료\n",
      "진행 상황: 400 / 500 문장 처리 완료\n",
      "저장 완료: Ikkyun_1000.jsonl / Ikkyun_1000.csv\n",
      "총 샘플 수: 1000개\n"
     ]
    }
   ],
   "source": [
    "# 라이브러리 로드\n",
    "import pandas as pd\n",
    "import json\n",
    "from dotenv import load_dotenv\n",
    "from langchain.prompts import load_prompt\n",
    "from langchain.output_parsers import PydanticOutputParser\n",
    "from langchain_openai import ChatOpenAI\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "# .env 로드\n",
    "load_dotenv()\n",
    "\n",
    "\n",
    "# 변경된 Pydantic 출력 모델 정의\n",
    "class SarcasmPair(BaseModel):\n",
    "    context: str = Field(description=\"리뷰 내용을 요약한 문맥\")\n",
    "    sarcastic_version: str = Field(description=\"풍자적으로 재작성된 문장\")\n",
    "    non_sarcastic_version: str = Field(description=\"풍자 없이 사실만을 전달한 문장\")\n",
    "    sarcastic_explanation: str = Field(\n",
    "        description=\"풍자 문장이 왜 풍자인지에 대한 설명\"\n",
    "    )\n",
    "    non_sarcastic_explanation: str = Field(\n",
    "        description=\"비풍자 문장이 왜 풍자가 아닌지에 대한 설명\"\n",
    "    )\n",
    "\n",
    "\n",
    "# Output parser\n",
    "parser = PydanticOutputParser(pydantic_object=SarcasmPair)\n",
    "\n",
    "# 프롬프트 로딩\n",
    "prompt = load_prompt(\"sarcasm_prompt.yaml\", encoding=\"utf-8\")\n",
    "\n",
    "# 모델 설정\n",
    "llm_4o = ChatOpenAI(temperature=0.5, model_name=\"gpt-4o\")\n",
    "llm_mini = ChatOpenAI(temperature=0.5, model_name=\"gpt-4o-mini\")\n",
    "\n",
    "chain_4o = prompt | llm_4o | parser\n",
    "chain_mini = prompt | llm_mini | parser\n",
    "\n",
    "# 리뷰 500개 로드\n",
    "df = pd.read_csv(\"negative_reviews.csv\")\n",
    "sample_df = df.sample(n=500, random_state=777).reset_index(drop=True)\n",
    "\n",
    "# 실행\n",
    "results = []\n",
    "for idx, text in enumerate(sample_df[\"text\"]):\n",
    "    model_chain = chain_4o if len(text) <= 50 else chain_mini\n",
    "    try:\n",
    "        result = model_chain.invoke({\"original\": text})\n",
    "\n",
    "        # 풍자 버전\n",
    "        results.append(\n",
    "            {\n",
    "                \"context\": result.context,\n",
    "                \"response\": result.sarcastic_version,\n",
    "                \"label\": \"Sarcasm\",\n",
    "                \"explanation\": result.sarcastic_explanation,\n",
    "            }\n",
    "        )\n",
    "\n",
    "        # 비풍자 버전\n",
    "        results.append(\n",
    "            {\n",
    "                \"context\": result.context,\n",
    "                \"response\": result.non_sarcastic_version,\n",
    "                \"label\": \"Non-Sarcasm\",\n",
    "                \"explanation\": result.non_sarcastic_explanation,\n",
    "            }\n",
    "        )\n",
    "\n",
    "        if idx % 100 == 0:\n",
    "            print(f\"진행 상황: {idx} / 500 문장 처리 완료\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"[⚠️] 오류 발생 - {text[:30]}... → {e}\")\n",
    "        continue\n",
    "\n",
    "# 저장\n",
    "jsonl_path = \"review_train.jsonl\"\n",
    "csv_path = \"review_train.csv\"\n",
    "\n",
    "with open(jsonl_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    for item in results:\n",
    "        f.write(json.dumps(item, ensure_ascii=False) + \"\\n\")\n",
    "\n",
    "pd.DataFrame(results).to_csv(csv_path, index=False, encoding=\"utf-8-sig\")\n",
    "\n",
    "print(f\"저장 완료: {jsonl_path} / {csv_path}\")\n",
    "print(f\"총 샘플 수: {len(results)}개\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4818bb4b",
   "metadata": {},
   "source": [
    "### 결과요약\n",
    "\n",
    "토큰 사용량: 373,209  \n",
    "비용: $1.05  \n",
    "런타임: 28분  \n",
    "비고: 품질 괜찮음."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9da70c2b",
   "metadata": {},
   "source": [
    "## 🐼 테스트셋 200개\n",
    "트레이닝셋과 겹치지 않는 부정 리뷰 100개 (200 rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9915b454",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No `_type` key found, defaulting to `prompt`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[테스트셋 진행 상황] 0 / 100 리뷰 처리 완료\n",
      "[테스트셋 진행 상황] 20 / 100 리뷰 처리 완료\n",
      "[테스트셋 진행 상황] 40 / 100 리뷰 처리 완료\n",
      "[테스트셋 진행 상황] 60 / 100 리뷰 처리 완료\n",
      "[테스트셋 진행 상황] 80 / 100 리뷰 처리 완료\n",
      "테스트셋 저장 완료: Ikkyun_test200.jsonl / Ikkyun_test200.csv\n",
      "총 샘플 수: 200개\n"
     ]
    }
   ],
   "source": [
    "# 라이브러리 로드\n",
    "import pandas as pd\n",
    "import json\n",
    "from dotenv import load_dotenv\n",
    "from langchain.prompts import load_prompt\n",
    "from langchain.output_parsers import PydanticOutputParser\n",
    "from langchain_openai import ChatOpenAI\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "# .env 로드\n",
    "load_dotenv()\n",
    "\n",
    "\n",
    "# 출력 모델 정의\n",
    "class SarcasmPair(BaseModel):\n",
    "    context: str = Field(description=\"리뷰 내용을 요약한 문맥\")\n",
    "    sarcastic_version: str = Field(description=\"풍자적으로 재작성된 문장\")\n",
    "    non_sarcastic_version: str = Field(description=\"풍자 없이 사실만을 전달한 문장\")\n",
    "    sarcastic_explanation: str = Field(\n",
    "        description=\"풍자 문장이 왜 풍자인지에 대한 설명\"\n",
    "    )\n",
    "    non_sarcastic_explanation: str = Field(\n",
    "        description=\"비풍자 문장이 왜 풍자가 아닌지에 대한 설명\"\n",
    "    )\n",
    "\n",
    "\n",
    "# 파서 설정\n",
    "parser = PydanticOutputParser(pydantic_object=SarcasmPair)\n",
    "\n",
    "# 프롬프트 및 체인 설정\n",
    "prompt = load_prompt(\"sarcasm_prompt.yaml\", encoding=\"utf-8\")\n",
    "llm_4o = ChatOpenAI(temperature=0.5, model_name=\"gpt-4o\")\n",
    "llm_mini = ChatOpenAI(temperature=0.5, model_name=\"gpt-4o-mini\")\n",
    "chain_4o = prompt | llm_4o | parser\n",
    "chain_mini = prompt | llm_mini | parser\n",
    "\n",
    "# 전체 리뷰 로드\n",
    "df_all = pd.read_csv(\"negative_reviews.csv\")\n",
    "\n",
    "# 기존에 사용된 500개 리뷰 로드r\n",
    "used_df = pd.read_csv(\"review_train.csv\")\n",
    "used_texts = set(used_df[\"context\"].unique())  # context 기준으로 중복 제거\n",
    "\n",
    "# 사용되지 않은 리뷰 필터링\n",
    "unused_df = df_all[~df_all[\"text\"].isin(used_texts)].reset_index(drop=True)\n",
    "\n",
    "# 새로 샘플링할 100개 추출\n",
    "sample_df = unused_df.sample(n=100, random_state=123).reset_index(drop=True)\n",
    "\n",
    "# 생성 실행\n",
    "results = []\n",
    "for idx, text in enumerate(sample_df[\"text\"]):\n",
    "    model_chain = chain_4o if len(text) <= 50 else chain_mini\n",
    "    try:\n",
    "        result = model_chain.invoke({\"original\": text})\n",
    "\n",
    "        results.append(\n",
    "            {\n",
    "                \"context\": result.context,\n",
    "                \"response\": result.sarcastic_version,\n",
    "                \"label\": \"Sarcasm\",\n",
    "                \"explanation\": result.sarcastic_explanation,\n",
    "            }\n",
    "        )\n",
    "        results.append(\n",
    "            {\n",
    "                \"context\": result.context,\n",
    "                \"response\": result.non_sarcastic_version,\n",
    "                \"label\": \"Non-Sarcasm\",\n",
    "                \"explanation\": result.non_sarcastic_explanation,\n",
    "            }\n",
    "        )\n",
    "\n",
    "        if idx % 20 == 0:\n",
    "            print(f\"[테스트셋 진행 상황] {idx} / 100 리뷰 처리 완료\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"[⚠️] 오류 - {text[:30]}... → {e}\")\n",
    "        continue\n",
    "\n",
    "# 저장\n",
    "jsonl_path = \"review_test.jsonl\"\n",
    "csv_path = \"review_test.csv\"\n",
    "\n",
    "with open(jsonl_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    for item in results:\n",
    "        f.write(json.dumps(item, ensure_ascii=False) + \"\\n\")\n",
    "\n",
    "pd.DataFrame(results).to_csv(csv_path, index=False, encoding=\"utf-8-sig\")\n",
    "\n",
    "print(f\"테스트셋 저장 완료: {jsonl_path} / {csv_path}\")\n",
    "print(f\"총 샘플 수: {len(results)}개\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c79ea369",
   "metadata": {},
   "source": [
    "### 결과요약\n",
    "\n",
    "토큰 사용량: 74,968  \n",
    "비용: $0.22  \n",
    "런타임: 7분  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ebb5310",
   "metadata": {},
   "source": [
    "## 🐻‍❄️ 추가 데이터 250개\n",
    "겹치지 않는 부정 리뷰 125개 (250 rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d10a1a1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No `_type` key found, defaulting to `prompt`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[진행 상황] 0 / 125 리뷰 처리 완료\n",
      "[진행 상황] 25 / 125 리뷰 처리 완료\n",
      "[진행 상황] 50 / 125 리뷰 처리 완료\n",
      "[진행 상황] 75 / 125 리뷰 처리 완료\n",
      "[진행 상황] 100 / 125 리뷰 처리 완료\n",
      "저장 완료: Ikkyun_new.jsonl / Ikkyun_new.csv\n",
      "총 생성 샘플 수: 250개\n"
     ]
    }
   ],
   "source": [
    "# 라이브러리 로드\n",
    "import pandas as pd\n",
    "import json\n",
    "from dotenv import load_dotenv\n",
    "from langchain.prompts import load_prompt\n",
    "from langchain.output_parsers import PydanticOutputParser\n",
    "from langchain_openai import ChatOpenAI\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "# .env 로드\n",
    "load_dotenv()\n",
    "\n",
    "\n",
    "# 출력 모델 정의\n",
    "class SarcasmPair(BaseModel):\n",
    "    context: str = Field(description=\"리뷰 내용을 요약한 문맥\")\n",
    "    sarcastic_version: str = Field(description=\"풍자적으로 재작성된 문장\")\n",
    "    non_sarcastic_version: str = Field(description=\"풍자 없이 사실만을 전달한 문장\")\n",
    "    sarcastic_explanation: str = Field(\n",
    "        description=\"풍자 문장이 왜 풍자인지에 대한 설명\"\n",
    "    )\n",
    "    non_sarcastic_explanation: str = Field(\n",
    "        description=\"비풍자 문장이 왜 풍자가 아닌지에 대한 설명\"\n",
    "    )\n",
    "\n",
    "\n",
    "# 파서 설정\n",
    "parser = PydanticOutputParser(pydantic_object=SarcasmPair)\n",
    "\n",
    "# 프롬프트 및 체인 설정\n",
    "prompt = load_prompt(\"sarcasm_prompt.yaml\", encoding=\"utf-8\")\n",
    "llm_4o = ChatOpenAI(temperature=0.5, model_name=\"gpt-4o\")\n",
    "llm_mini = ChatOpenAI(temperature=0.5, model_name=\"gpt-4o-mini\")\n",
    "chain_4o = prompt | llm_4o | parser\n",
    "chain_mini = prompt | llm_mini | parser\n",
    "\n",
    "# 전체 리뷰 로드\n",
    "df_all = pd.read_csv(\"negative_reviews.csv\")\n",
    "\n",
    "# 기존 사용된 context 로드 (train + test)\n",
    "train_df = pd.read_csv(\"review_train.csv\")\n",
    "test_df = pd.read_csv(\"review_test.csv\")\n",
    "used_contexts = set(train_df[\"context\"].unique()).union(\n",
    "    set(test_df[\"context\"].unique())\n",
    ")\n",
    "\n",
    "# 사용되지 않은 리뷰 필터링\n",
    "unused_df = df_all[~df_all[\"text\"].isin(used_contexts)].reset_index(drop=True)\n",
    "\n",
    "# 125개 샘플링\n",
    "sample_df = unused_df.sample(n=125, random_state=456).reset_index(drop=True)\n",
    "\n",
    "# 생성 시작\n",
    "results = []\n",
    "for idx, text in enumerate(sample_df[\"text\"]):\n",
    "    model_chain = chain_4o if len(text) <= 50 else chain_mini\n",
    "    try:\n",
    "        result = model_chain.invoke({\"original\": text})\n",
    "\n",
    "        results.append(\n",
    "            {\n",
    "                \"context\": result.context,\n",
    "                \"response\": result.sarcastic_version,\n",
    "                \"label\": \"Sarcasm\",\n",
    "                \"explanation\": result.sarcastic_explanation,\n",
    "            }\n",
    "        )\n",
    "        results.append(\n",
    "            {\n",
    "                \"context\": result.context,\n",
    "                \"response\": result.non_sarcastic_version,\n",
    "                \"label\": \"Non-Sarcasm\",\n",
    "                \"explanation\": result.non_sarcastic_explanation,\n",
    "            }\n",
    "        )\n",
    "\n",
    "        if idx % 25 == 0:\n",
    "            print(f\"[진행 상황] {idx} / 125 리뷰 처리 완료\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"[⚠️] 오류 - {text[:30]}... → {e}\")\n",
    "        continue\n",
    "\n",
    "# 저장\n",
    "jsonl_path = \"Ikkyun_new.jsonl\"\n",
    "csv_path = \"Ikkyun_new.csv\"\n",
    "\n",
    "with open(jsonl_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    for item in results:\n",
    "        f.write(json.dumps(item, ensure_ascii=False) + \"\\n\")\n",
    "\n",
    "pd.DataFrame(results).to_csv(csv_path, index=False, encoding=\"utf-8-sig\")\n",
    "\n",
    "print(f\"저장 완료: {jsonl_path} / {csv_path}\")\n",
    "print(f\"총 생성 샘플 수: {len(results)}개\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5c43214",
   "metadata": {},
   "source": [
    "### 결과요약\n",
    "\n",
    "토큰 사용량: 93,899  \n",
    "비용: $0.29  \n",
    "런타임: 7분  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain-kr-G84JNwzB-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
